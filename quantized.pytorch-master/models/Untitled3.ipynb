{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-157e1c2d6ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;31m#         return output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-157e1c2d6ecd>\u001b[0m in \u001b[0;36mNet\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Net' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Optional: Data Parallelism\n",
    "==========================\n",
    "**Authors**: `Sung Kim <https://github.com/hunkim>`_ and `Jenny Kang <https://github.com/jennykang>`_\n",
    "\n",
    "In this tutorial, we will learn how to use multiple GPUs using ``DataParallel``.\n",
    "\n",
    "It's very easy to use GPUs with PyTorch. You can put the model on a GPU:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.to(device)\n",
    "\n",
    "Then, you can copy all your tensors to the GPU:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    mytensor = my_tensor.to(device)\n",
    "\n",
    "Please note that just calling ``my_tensor.to(device)`` returns a new copy of\n",
    "``my_tensor`` on GPU instead of rewriting ``my_tensor``. You need to assign it to\n",
    "a new tensor and use that tensor on the GPU.\n",
    "\n",
    "It's natural to execute your forward, backward propagations on multiple GPUs.\n",
    "However, Pytorch will only use one GPU by default. You can easily run your\n",
    "operations on multiple GPUs by making your model run parallelly using\n",
    "``DataParallel``:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "That's the core behind this tutorial. We will explore it in more detail below.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Imports and parameters\n",
    "# ----------------------\n",
    "#\n",
    "# Import PyTorch modules and define parameters.\n",
    "#\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from modules.quantize import quantize, quantize_grad, QConv2d, QLinear, RangeBN\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "\n",
    "# Specify Parameters\n",
    "output_file = 'ant_trials.csv'\n",
    "max_bits = 100000\n",
    "conv1_w = 0\n",
    "conv2_w = 0\n",
    "fc1_w = 0\n",
    "fc2_w = 0\n",
    "fc3_w = 0\n",
    "\n",
    "######################################################################\n",
    "# Device\n",
    "#\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "######################################################################\n",
    "# Dummy DataSet\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1].\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../../../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "########################################################################\n",
    "#\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Simple Model\n",
    "# ------------\n",
    "#\n",
    "# For the demo, our model just gets an input, performs a linear operation, and\n",
    "# gives an output. However, you can use ``DataParallel`` on any model (CNN, RNN,\n",
    "# Capsule Net etc.)\n",
    "#\n",
    "# We've placed a print statement inside the model to monitor the size of input\n",
    "# and output tensors.\n",
    "# Please pay attention to what is printed at batch rank 0.\n",
    "#\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     # Our model\n",
    "\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         output = self.fc(input)\n",
    "#         print(\"\\tIn Model: input size\", input.size(),\n",
    "#               \"output size\", output.size())\n",
    "\n",
    "#         return output\n",
    "def runNet():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.conv1 = QConv2d(3, 6, 5, num_bits_weight = conv1_w)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = QConv2d(6, 16, 5, num_bits_weight = conv2_w)\n",
    "            self.fc1 = QLinear(16 * 5 * 5, 120, num_bits_weight = fc1_w)\n",
    "            self.fc2 = QLinear(120, 84, num_bits_weight = fc2_w)\n",
    "            self.fc3 = QLinear(84, 10, num_bits_weight = fc3_w)\n",
    "\n",
    "        def update(self):\n",
    "            self.__init__()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 16 * 5 * 5)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # Create Model and DataParallel\n",
    "    # -----------------------------\n",
    "    #\n",
    "    # This is the core part of the tutorial. First, we need to make a model instance\n",
    "    # and check if we have multiple GPUs. If we have multiple GPUs, we can wrap\n",
    "    # our model using ``nn.DataParallel``. Then we can put our model on GPUs by\n",
    "    # ``model.to(device)``\n",
    "    #\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # Run the Model\n",
    "    # -------------\n",
    "    #\n",
    "    # Now we can see the sizes of input and output tensors.\n",
    "    #\n",
    "\n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    ########################################################################\n",
    "    # 4. Train the network\n",
    "    # ^^^^^^^^^^^^^^^^^^^^\n",
    "    #\n",
    "    # This is when things start to get interesting.\n",
    "    # We simply have to loop over our data iterator, and feed the inputs to the\n",
    "    # network and optimize.\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    # Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    ########################################################################\n",
    "    # That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
    "    # a class out of 10 classes).\n",
    "    # Seems like the network learnt something.\n",
    "    #\n",
    "    # Hmmm, what are the classes that performed well, and the classes that did\n",
    "    # not perform well:\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    ########################################################################\n",
    "    #Append CSV\n",
    "    fields = ['']*11\n",
    "    fields[0] = str(100 * correct / total)\n",
    "    for i in range(10):\n",
    "        fields[i+1] = str(100 * class_correct[i] / class_total[i])\n",
    "    outfile = open(output_file, 'a', newline='')\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(fields)\n",
    "    outfile.close()\n",
    "\n",
    "for a in range(3,9):\n",
    "    conv1_w = a\n",
    "    for b in range(1,9):\n",
    "        conv2_w = b\n",
    "        for c in range(1,9):\n",
    "            fc1_w = c\n",
    "            for d in range(1,9):\n",
    "                fc2_w = d\n",
    "                for e in range(1,9):\n",
    "                    fc3_w = e\n",
    "                    totBits = a * 4704 + b * 1600 + c * 48000 + d * 10080 + e * 840\n",
    "                    if totBits < max_bits:\n",
    "                        runNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
